{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install flask-ngrok openpyxl lime scikit-learn --quiet"
      ],
      "metadata": {
        "id": "fGa3AXEy0Y1A"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# === STEP 1: Load Dataset ===\n",
        "train_file = \"/content/credit_score_training_data.xlsx\"\n",
        "df = pd.read_excel(train_file)\n",
        "\n",
        "# Encode categorical features\n",
        "label_encoders = {}\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Split into features and target\n",
        "X = df.drop(columns=['CREDIT_SCORE'])\n",
        "y = df['CREDIT_SCORE']\n",
        "\n",
        "# === STEP 2: Define Models to Compare ===\n",
        "models_to_try = {\n",
        "    \"RandomForest\": lambda seed: RandomForestRegressor(random_state=seed),\n",
        "    \"GradientBoosting\": lambda seed: GradientBoostingRegressor(random_state=seed),\n",
        "    \"MLPRegressor\": lambda seed: MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=seed)\n",
        "}\n",
        "\n",
        "# === STEP 3: Train and Evaluate Models ===\n",
        "best_r2 = float('-inf')\n",
        "best_model = None\n",
        "best_model_name = \"\"\n",
        "best_scaler = None\n",
        "best_comparison_df = None\n",
        "best_epoch = None\n",
        "\n",
        "for model_name, model_func in models_to_try.items():\n",
        "    print(f\"\\nTraining model: {model_name}\")\n",
        "\n",
        "    for epoch in range(1, 21):\n",
        "        # Train-test split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=epoch\n",
        "        )\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Initialize and train model\n",
        "        model = model_func(epoch)\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        # Metrics\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = sqrt(mse)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"Epoch {epoch:2d} | R²: {r2:.4f} | RMSE: {rmse:.2f} | MAE: {mae:.2f}\")\n",
        "\n",
        "        # Track best model overall\n",
        "        if r2 > best_r2:\n",
        "            best_r2 = r2\n",
        "            best_model = model\n",
        "            best_model_name = model_name\n",
        "            best_scaler = scaler\n",
        "            best_epoch = epoch\n",
        "            best_comparison_df = pd.DataFrame({\n",
        "                'Actual': y_test.values,\n",
        "                'Predicted': y_pred.round(2)\n",
        "            })\n",
        "\n",
        "# === STEP 4: Save the Best Model ===\n",
        "with open(\"credit_score_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(best_model, f)\n",
        "with open(\"scaler.pkl\", \"wb\") as f:\n",
        "    pickle.dump(best_scaler, f)\n",
        "with open(\"encoders.pkl\", \"wb\") as f:\n",
        "    pickle.dump(label_encoders, f)\n",
        "\n",
        "# === STEP 5: Summary ===\n",
        "print(\"\\nBest model saved successfully.\")\n",
        "print(f\"Best Model: {best_model_name} from epoch {best_epoch}\")\n",
        "print(f\"Best R² Score: {best_r2:.4f}\")\n",
        "print(\"\\nSample Prediction Results:\")\n",
        "print(best_comparison_df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgAaAlEwwSCy",
        "outputId": "c4b0d120-2cff-499b-8f49-37115af7c472"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model: RandomForest\n",
            "Epoch  1 | R²: 0.5964 | RMSE: 38.12 | MAE: 27.30\n",
            "Epoch  2 | R²: -0.6000 | RMSE: 18.97 | MAE: 15.60\n",
            "Epoch  3 | R²: -1.2059 | RMSE: 14.85 | MAE: 14.85\n",
            "Epoch  4 | R²: 0.7144 | RMSE: 42.75 | MAE: 34.35\n",
            "Epoch  5 | R²: 0.7739 | RMSE: 38.04 | MAE: 32.30\n",
            "Epoch  6 | R²: -1.9266 | RMSE: 42.77 | MAE: 33.45\n",
            "Epoch  7 | R²: -5.1943 | RMSE: 49.78 | MAE: 41.85\n",
            "Epoch  8 | R²: 0.1008 | RMSE: 47.41 | MAE: 39.55\n",
            "Epoch  9 | R²: -30.7743 | RMSE: 56.37 | MAE: 52.45\n",
            "Epoch 10 | R²: -0.0600 | RMSE: 41.18 | MAE: 30.20\n",
            "Epoch 11 | R²: -1.1464 | RMSE: 51.28 | MAE: 38.95\n",
            "Epoch 12 | R²: -5.4163 | RMSE: 50.66 | MAE: 43.45\n",
            "Epoch 13 | R²: 0.9728 | RMSE: 9.90 | MAE: 9.60\n",
            "Epoch 14 | R²: -6.2340 | RMSE: 53.79 | MAE: 50.40\n",
            "Epoch 15 | R²: -2.4694 | RMSE: 18.63 | MAE: 16.65\n",
            "Epoch 16 | R²: -1.9510 | RMSE: 17.18 | MAE: 16.45\n",
            "Epoch 17 | R²: 0.8990 | RMSE: 1.59 | MAE: 1.55\n",
            "Epoch 18 | R²: 0.6723 | RMSE: 37.21 | MAE: 27.10\n",
            "Epoch 19 | R²: 0.5774 | RMSE: 6.50 | MAE: 6.50\n",
            "Epoch 20 | R²: 0.4080 | RMSE: 7.69 | MAE: 7.60\n",
            "\n",
            "Training model: GradientBoosting\n",
            "Epoch  1 | R²: 0.6747 | RMSE: 34.22 | MAE: 25.00\n",
            "Epoch  2 | R²: 0.3046 | RMSE: 12.51 | MAE: 11.84\n",
            "Epoch  3 | R²: -0.9097 | RMSE: 13.82 | MAE: 11.32\n",
            "Epoch  4 | R²: 0.7534 | RMSE: 39.73 | MAE: 31.67\n",
            "Epoch  5 | R²: 0.8467 | RMSE: 31.32 | MAE: 25.34\n",
            "Epoch  6 | R²: -0.2385 | RMSE: 27.82 | MAE: 25.00\n",
            "Epoch  7 | R²: -4.1337 | RMSE: 45.32 | MAE: 40.44\n",
            "Epoch  8 | R²: 0.4672 | RMSE: 36.50 | MAE: 27.05\n",
            "Epoch  9 | R²: -29.8691 | RMSE: 55.56 | MAE: 49.55\n",
            "Epoch 10 | R²: 0.2735 | RMSE: 34.09 | MAE: 24.15\n",
            "Epoch 11 | R²: 0.5394 | RMSE: 23.75 | MAE: 20.00\n",
            "Epoch 12 | R²: -4.8664 | RMSE: 48.44 | MAE: 39.15\n",
            "Epoch 13 | R²: 0.9962 | RMSE: 3.71 | MAE: 3.56\n",
            "Epoch 14 | R²: -2.4363 | RMSE: 37.07 | MAE: 32.89\n",
            "Epoch 15 | R²: -5.4392 | RMSE: 25.38 | MAE: 22.39\n",
            "Epoch 16 | R²: -6.2655 | RMSE: 26.95 | MAE: 24.05\n",
            "Epoch 17 | R²: -2.1593 | RMSE: 8.89 | MAE: 8.34\n",
            "Epoch 18 | R²: 0.7121 | RMSE: 34.88 | MAE: 26.73\n",
            "Epoch 19 | R²: -0.7577 | RMSE: 13.26 | MAE: 12.62\n",
            "Epoch 20 | R²: -0.0040 | RMSE: 10.02 | MAE: 9.48\n",
            "\n",
            "Training model: MLPRegressor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 | R²: -51.8115 | RMSE: 436.03 | MAE: 425.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  2 | R²: -111.4801 | RMSE: 159.08 | MAE: 143.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  3 | R²: -1482.7265 | RMSE: 385.19 | MAE: 380.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  4 | R²: -14.2913 | RMSE: 312.83 | MAE: 262.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  5 | R²: -20.4079 | RMSE: 370.15 | MAE: 355.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  6 | R²: -121.9361 | RMSE: 277.19 | MAE: 269.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  7 | R²: -210.0310 | RMSE: 290.54 | MAE: 283.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  8 | R²: -56.2790 | RMSE: 378.41 | MAE: 373.53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  9 | R²: -1573.6370 | RMSE: 396.82 | MAE: 395.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | R²: -45.0735 | RMSE: 271.51 | MAE: 271.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 | R²: -63.2163 | RMSE: 280.47 | MAE: 249.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 | R²: -199.2384 | RMSE: 283.01 | MAE: 282.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 | R²: -2.3734 | RMSE: 110.20 | MAE: 102.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 | R²: -608.2430 | RMSE: 493.66 | MAE: 454.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 | R²: -1086.5404 | RMSE: 329.78 | MAE: 315.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 | R²: -993.7566 | RMSE: 315.40 | MAE: 298.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 | R²: -5713.4783 | RMSE: 377.97 | MAE: 364.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 | R²: -53.4129 | RMSE: 479.47 | MAE: 479.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 | R²: -1383.1646 | RMSE: 372.04 | MAE: 363.04\n",
            "Epoch 20 | R²: -1382.9552 | RMSE: 372.02 | MAE: 358.99\n",
            "\n",
            "Best model saved successfully.\n",
            "Best Model: GradientBoosting from epoch 13\n",
            "Best R² Score: 0.9962\n",
            "\n",
            "Sample Prediction Results:\n",
            "   Actual  Predicted\n",
            "0     640     642.48\n",
            "1     760     755.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox0dHOIrk5Md",
        "outputId": "6ed1fd1e-e0e8-40a3-ac8c-f346b4ca8346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Prediction Results:\n",
            "\n",
            "   Predicted Credit Score Risk Category  \\\n",
            "0                  650.00   Medium Risk   \n",
            "1                  750.00   Medium Risk   \n",
            "2                  720.00   Medium Risk   \n",
            "3                  642.48     High Risk   \n",
            "4                  780.00      Low Risk   \n",
            "5                  755.37      Low Risk   \n",
            "6                  700.00   Medium Risk   \n",
            "7                  730.00   Medium Risk   \n",
            "8                  800.00      Low Risk   \n",
            "9                  600.00     High Risk   \n",
            "\n",
            "                                   Decision  \\\n",
            "0       Possible Loan Approval with Caution   \n",
            "1       Possible Loan Approval with Caution   \n",
            "2       Possible Loan Approval with Caution   \n",
            "3  Loan Likely Rejected or Needs Collateral   \n",
            "4                      Likely Loan Approval   \n",
            "5                      Likely Loan Approval   \n",
            "6       Possible Loan Approval with Caution   \n",
            "7       Possible Loan Approval with Caution   \n",
            "8                      Likely Loan Approval   \n",
            "9  Loan Likely Rejected or Needs Collateral   \n",
            "\n",
            "                                         Explanation  \n",
            "0  Because the condition 'LOAN_AMOUNT <= -0.79' w...  \n",
            "1  Because the condition 'INTEREST_RATE <= -0.58'...  \n",
            "2  Because the condition '-0.29 < INCOME <= 0.98'...  \n",
            "3  Because the condition 'LOAN_AMOUNT <= -0.79' w...  \n",
            "4  Because the condition 'LOAN_AMOUNT > 0.82' was...  \n",
            "5  Because the condition '-0.03 < LOAN_TERM <= 0....  \n",
            "6  Because the condition '-0.84 < INCOME <= -0.29...  \n",
            "7  Because the condition '-0.29 < INCOME <= 0.98'...  \n",
            "8  Because the condition 'LOAN_AMOUNT > 0.82' was...  \n",
            "9  Because the condition 'LOAN_AMOUNT <= -0.79' w...  \n"
          ]
        }
      ],
      "source": [
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "test_file = \"/content/TEST_DATA.xlsx\"  # Replace with your path\n",
        "\n",
        "try:\n",
        "    input_df = pd.read_excel(test_file)\n",
        "\n",
        "    required_cols = ['AGE', 'INCOME', 'EMPLOYMENT_STATUS', 'LOAN_AMOUNT', 'LOAN_TERM',\n",
        "                     'INTEREST_RATE', 'NUM_OF_DEPENDENTS', 'MARITAL_STATUS', 'EDUCATION_LEVEL']\n",
        "\n",
        "    if not set(required_cols).issubset(input_df.columns):\n",
        "        print(f\"Missing columns: {required_cols}\")\n",
        "    else:\n",
        "        model = pickle.load(open(\"credit_score_model.pkl\", \"rb\"))\n",
        "        scaler = pickle.load(open(\"scaler.pkl\", \"rb\"))\n",
        "        label_encoders = pickle.load(open(\"encoders.pkl\", \"rb\"))\n",
        "\n",
        "        for col in input_df.select_dtypes(include=['object']).columns:\n",
        "            if col in label_encoders:\n",
        "                le = label_encoders[col]\n",
        "                known_classes = set(le.classes_)\n",
        "                input_df[col] = input_df[col].apply(lambda x: le.transform([x])[0] if x in known_classes else -1)\n",
        "            else:\n",
        "                input_df[col] = input_df[col].astype('category').cat.codes\n",
        "\n",
        "        input_scaled = scaler.transform(input_df[required_cols])\n",
        "        predictions = model.predict(input_scaled)\n",
        "\n",
        "        # LIME Explainer Setup\n",
        "        explainer = LimeTabularExplainer(\n",
        "            training_data=X_train_scaled,\n",
        "            feature_names=X.columns.tolist(),\n",
        "            mode=\"regression\"\n",
        "        )\n",
        "\n",
        "        risk_categories, decisions, explanations = [], [], []\n",
        "\n",
        "        for i, score in enumerate(predictions):\n",
        "            if score >= 750:\n",
        "                risk = \"Low Risk\"\n",
        "                decision = \"Likely Loan Approval\"\n",
        "            elif score >= 650:\n",
        "                risk = \"Medium Risk\"\n",
        "                decision = \"Possible Loan Approval with Caution\"\n",
        "            else:\n",
        "                risk = \"High Risk\"\n",
        "                decision = \"Loan Likely Rejected or Needs Collateral\"\n",
        "\n",
        "            risk_categories.append(risk)\n",
        "            decisions.append(decision)\n",
        "\n",
        "            # Get LIME explanation\n",
        "            exp = explainer.explain_instance(input_scaled[i], model.predict, num_features=5)\n",
        "            explanation_sentences = []\n",
        "            for feature, weight in exp.as_list():\n",
        "                impact = \"increased\" if weight > 0 else \"decreased\"\n",
        "                explanation_sentences.append(\n",
        "                    f\"Because the condition '{feature}' was met, it {impact} the predicted credit score.\"\n",
        "                )\n",
        "            explanation_str = \" \".join(explanation_sentences)\n",
        "            explanations.append(explanation_str)\n",
        "\n",
        "        # Compile results\n",
        "        result = input_df.copy()\n",
        "        result[\"Predicted Credit Score\"] = predictions.round(2)\n",
        "        result[\"Risk Category\"] = risk_categories\n",
        "        result[\"Decision\"] = decisions\n",
        "        result[\"Explanation\"] = explanations\n",
        "\n",
        "        # Display result\n",
        "        print(\"Final Prediction Results:\\n\")\n",
        "        print(result[[\"Predicted Credit Score\", \"Risk Category\", \"Decision\", \"Explanation\"]])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Full Flask App Script\n",
        "import json\n",
        "from flask import Flask, request, jsonify, render_template_string, redirect, url_for\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "# Load model, scaler, encoders\n",
        "model = pickle.load(open(\"credit_score_model.pkl\", \"rb\"))\n",
        "scaler = pickle.load(open(\"scaler.pkl\", \"rb\"))\n",
        "label_encoders = pickle.load(open(\"encoders.pkl\", \"rb\"))\n",
        "\n",
        "# Create users file if it doesn't exist\n",
        "if not os.path.exists(\"users.json\"):\n",
        "    with open(\"users.json\", \"w\") as f:\n",
        "        json.dump({}, f)\n",
        "\n",
        "# HTML Templates\n",
        "login_page = '''\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head><title>Login or Signup</title></head>\n",
        "<body style=\"font-family:sans-serif;text-align:center;margin-top:10%;\">\n",
        "    <h2>Login or Signup</h2>\n",
        "    <form method=\"post\" action=\"/auth\">\n",
        "        <input name=\"username\" placeholder=\"Username\" required><br><br>\n",
        "        <input name=\"password\" type=\"password\" placeholder=\"Password\" required><br><br>\n",
        "        <select name=\"mode\">\n",
        "            <option value=\"login\">Login</option>\n",
        "            <option value=\"signup\">Sign Up</option>\n",
        "        </select><br><br>\n",
        "        <button type=\"submit\">Continue</button>\n",
        "    </form>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "upload_page = '''\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head><title>Credit Score Checker</title></head>\n",
        "<body style=\"font-family:sans-serif;text-align:center;margin-top:5%;\">\n",
        "    <h2>Welcome, {{username}}</h2>\n",
        "    <form action=\"/check_score\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "        <p>Upload an Excel file (TEST_DATA.xlsx):</p>\n",
        "        <input type=\"file\" name=\"file\" accept=\".xlsx\" required><br><br>\n",
        "        <button type=\"submit\">Check Credit Score</button>\n",
        "    </form>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "result_template = '''\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head><title>Credit Score Result</title></head>\n",
        "<body style=\"font-family:sans-serif;margin:5%;\">\n",
        "    <h2>Prediction Result</h2>\n",
        "    <p><b>Predicted Credit Score:</b> {{score}}</p>\n",
        "    <p><b>Risk Category:</b> {{risk}}</p>\n",
        "    <p><b>Decision:</b> {{decision}}</p>\n",
        "    <p><b>Explanation:</b><br>{{explanation}}</p>\n",
        "    <a href=\"/\">Go back</a>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template_string(login_page)\n",
        "\n",
        "@app.route('/auth', methods=['POST'])\n",
        "def auth():\n",
        "    username = request.form['username']\n",
        "    password = request.form['password']\n",
        "    mode = request.form['mode']\n",
        "\n",
        "    with open(\"users.json\", \"r\") as f:\n",
        "        users = json.load(f)\n",
        "\n",
        "    if mode == \"signup\":\n",
        "        if username in users:\n",
        "            return \"User already exists. Go back and login.\"\n",
        "        users[username] = password\n",
        "        with open(\"users.json\", \"w\") as f:\n",
        "            json.dump(users, f)\n",
        "    elif mode == \"login\":\n",
        "        if username not in users or users[username] != password:\n",
        "            return \"Invalid credentials.\"\n",
        "\n",
        "    return render_template_string(upload_page, username=username)\n",
        "\n",
        "@app.route('/check_score', methods=['POST'])\n",
        "def check_score():\n",
        "    uploaded_file = request.files['file']\n",
        "    df = pd.read_excel(uploaded_file)\n",
        "\n",
        "    required_cols = ['AGE', 'INCOME', 'EMPLOYMENT_STATUS', 'LOAN_AMOUNT', 'LOAN_TERM',\n",
        "                     'INTEREST_RATE', 'NUM_OF_DEPENDENTS', 'MARITAL_STATUS', 'EDUCATION_LEVEL']\n",
        "\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        if col in label_encoders:\n",
        "            le = label_encoders[col]\n",
        "            df[col] = df[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category').cat.codes\n",
        "\n",
        "    input_scaled = scaler.transform(df[required_cols])\n",
        "    score = model.predict(input_scaled)[0]\n",
        "\n",
        "    if score >= 750:\n",
        "        risk = \"Low Risk\"\n",
        "        decision = \"Likely Loan Approval\"\n",
        "    elif score >= 650:\n",
        "        risk = \"Medium Risk\"\n",
        "        decision = \"Possible Loan Approval with Caution\"\n",
        "    else:\n",
        "        risk = \"High Risk\"\n",
        "        decision = \"Loan Likely Rejected or Needs Collateral\"\n",
        "\n",
        "    explainer = LimeTabularExplainer(training_data=input_scaled,\n",
        "                                     feature_names=required_cols,\n",
        "                                     mode=\"regression\")\n",
        "    exp = explainer.explain_instance(input_scaled[0], model.predict, num_features=5)\n",
        "    explanation = \" \".join([f\"Because the condition '{f}' was met, it {'increased' if w > 0 else 'decreased'} the predicted score.\" for f, w in exp.as_list()])\n",
        "\n",
        "    return render_template_string(result_template, score=round(score,2), risk=risk, decision=decision, explanation=explanation)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host='0.0.0.0', port=5000, debug=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvEEzvv13uSO",
        "outputId": "9e07c182-22cf-4025-a3bc-7b7c590017f6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok http 5000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0ZGrfAP5YwT",
        "outputId": "64b522a5-1ac9-4a78-85d8-847b8fe95c56"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR:  authentication failed: Usage of ngrok requires a verified account and authtoken.\n",
            "ERROR:  \n",
            "ERROR:  Sign up for an account: https://dashboard.ngrok.com/signup\n",
            "ERROR:  Install your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\r\n",
            "ERROR:  \r\n",
            "ERROR:  ERR_NGROK_4018\r\n",
            "ERROR:  https://ngrok.com/docs/errors/err_ngrok_4018\r\n",
            "ERROR:  \n"
          ]
        }
      ]
    }
  ]
}